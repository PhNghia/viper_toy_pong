import gym
import numpy as np
from joblib import load
from gym_env.toy_pong import ToyPong  # Äáº£m báº£o import Ä‘Ãºng mÃ´i trÆ°á»ng ToyPong

# Load cÃ¢y quyáº¿t Ä‘á»‹nh tá»« file
tree = load("log/viper_ToyPong-v0_587_20.joblib")

# Cháº¡y mÃ´i trÆ°á»ng ToyPong
class DecisionTreeAgent:
    def __init__(self, model):
        self.model = model

    def act(self, observation):
        # Reshape observation Ä‘á»ƒ phÃ¹ há»£p vá»›i input cá»§a cÃ¢y
        observation = np.array(observation).reshape(1, -1)
        return self.model.predict(observation)[0]  # Dá»± Ä‘oÃ¡n action tá»« cÃ¢y

# Táº¡o mÃ´i trÆ°á»ng ToyPong
# args = lambda: None
# args.render = True  # Hiá»ƒn thá»‹ game
# args.rand_ball_start = False  # KhÃ´ng khá»Ÿi táº¡o bÃ³ng ngáº«u nhiÃªn
# env = ToyPong(args)
args = type('', (), {})()  # Táº¡o má»™t object rá»—ng Ä‘á»ƒ truyá»n Ä‘á»‘i sá»‘
args.render = True  # Hiá»ƒn thá»‹ pygame
args.rand_ball_start = False  # Giá»¯ vá»‹ trÃ­ ban Ä‘áº§u cá»‘ Ä‘á»‹nh (cÃ³ thá»ƒ Ä‘á»•i)
env = ToyPong(args)

agent = DecisionTreeAgent(tree)

obs = env.reset()
done = False
step = 0

while not done:
    action = agent.act(obs)  # Chá»n action tá»« cÃ¢y quyáº¿t Ä‘á»‹nh
    # ğŸ”¹ In thÃ´ng tin quan trá»ng
    print(f"\nğŸ”¹ Step {step}")
    print(f"   - Observation: {obs}")  # Quan sÃ¡t cá»§a mÃ´i trÆ°á»ng
    print(f"   - Chá»n hÃ nh Ä‘á»™ng: {action}")
    obs, reward, done, _ = env.step(action)  # Thá»±c hiá»‡n bÆ°á»›c Ä‘i
    # ğŸ”¹ In káº¿t quáº£ sau khi thá»±c hiá»‡n action
    print(f"   - Reward: {reward}")
    print(f"   - Done: {done}")
    env.render()
    step += 1

env.close()
