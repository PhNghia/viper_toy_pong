(viper-env) C:\SGU-LEARN\nam4_hk2\seminar\viper-verifiable-rl-impl>python main.py train-viper --verbose 2 --env-name ToyPong-v0 --n-env 4 --ccp-alpha 0.0001 --total-timesteps 1_000_000
Training Viper on ToyPong-v0
Policy score: 764.8900 +/- 349.3123
Policy score: 530.1400 +/- 412.3154
Policy score: 735.7400 +/- 391.4173
Policy score: 734.6900 +/- 405.3918
Policy score: 821.2300 +/- 333.1618
Policy score: 833.5300 +/- 325.3354
Policy score: 930.5100 +/- 234.1870
Policy score: 871.9000 +/- 280.0755
Policy score: 951.5400 +/- 188.5334
Policy score: 873.7700 +/- 299.9004
Policy score: 763.2600 +/- 368.9895
Policy score: 722.3200 +/- 389.9302
Policy score: 820.7800 +/- 348.7777
Policy score: 948.7600 +/- 175.4372
Policy score: 884.7000 +/- 297.0221
Policy score: 849.3500 +/- 327.6193
Policy score: 943.1300 +/- 217.4934
Policy score: 877.1000 +/- 298.9362
Policy score: 845.6600 +/- 329.5778
Policy score: 863.7100 +/- 307.8378
Policy score: 851.8700 +/- 309.8492
Policy score: 845.5300 +/- 327.3615
Policy score: 905.8100 +/- 257.0632
Policy score: 889.3800 +/- 283.7892
Policy score: 873.1600 +/- 298.3144
Policy score: 906.5900 +/- 248.5300
Policy score: 940.7500 +/- 200.8391
Policy score: 937.3100 +/- 183.8060
Policy score: 887.4300 +/- 262.9407
Policy score: 845.8400 +/- 299.5956
Policy score: 843.9200 +/- 314.5981
Policy score: 839.3100 +/- 303.8849
Policy score: 896.6600 +/- 247.9515
Policy score: 930.1500 +/- 205.7015
Policy score: 932.1400 +/- 197.2540
Policy score: 926.1300 +/- 210.2261
Policy score: 939.3800 +/- 163.3559
Policy score: 948.2100 +/- 188.4185
Policy score: 935.2100 +/- 206.7279
Policy score: 927.8600 +/- 217.0305
Policy score: 971.6200 +/- 136.1384
Policy score: 971.0200 +/- 145.6384
Policy score: 942.6200 +/- 203.0679
Policy score: 948.8000 +/- 187.7358
Policy score: 941.2400 +/- 200.4613
Policy score: 894.1000 +/- 262.5863
Policy score: 971.9300 +/- 154.3162
Policy score: 957.1500 +/- 188.8814
Policy score: 941.7800 +/- 190.4220
Policy score: 975.5200 +/- 92.0672
Policy score: 912.6500 +/- 252.8625
Policy score: 965.1900 +/- 150.9303
Policy score: 965.4400 +/- 155.3654
Policy score: 987.7400 +/- 101.1076
Policy score: 955.5100 +/- 175.9364
Policy score: 930.5600 +/- 238.2780
Policy score: 947.6500 +/- 195.3792
Policy score: 966.4000 +/- 171.1173
Policy score: 948.6700 +/- 184.0427
Policy score: 950.7300 +/- 163.9772
Policy score: 954.0300 +/- 176.7267
Policy score: 952.5900 +/- 186.7764
Policy score: 979.1900 +/- 108.8177
Policy score: 892.0200 +/- 243.0030
Policy score: 881.0100 +/- 254.8781
Policy score: 857.6400 +/- 282.3941
Policy score: 957.4400 +/- 185.8607
Policy score: 873.4900 +/- 275.3771
Policy score: 930.1500 +/- 214.6286
Policy score: 912.1900 +/- 218.9489
Policy score: 858.2600 +/- 306.0729
Policy score: 963.6800 +/- 162.0763
Policy score: 959.4700 +/- 164.0503
Policy score: 917.7700 +/- 235.4683
Policy score: 933.5400 +/- 198.9664
Policy score: 879.7000 +/- 268.0166
Policy score: 956.4900 +/- 168.0701
Policy score: 991.9600 +/- 57.4059
Policy score: 978.0400 +/- 115.1738
Policy score: 928.6800 +/- 208.5538
Viper iteration complete. Dataset size: 1000000
Best policy:    77
Mean reward:    991.9600
Max depth:      24
# Leaves:       921
Saving to       ./log/viper_ToyPong-v0_0.0001_all-leaves_all-depth.joblib